---
phase: 02-storage-and-ddl
plan: 02-04
task: 2
total_tasks: 2
status: in_progress
last_updated: 2026-02-24T11:01:11.074Z
---

<current_state>
Implementing plan 02-04 (DDL-05 gap closure). Background writer thread approach is coded and compiles clean, but the SQLLogicTest restart section (section 10 of phase2_ddl.test) is failing: `list_semantic_views()` returns 0 rows after the `restart` statement. The CHECKPOINT call added to the background thread did not fix it.

The restart test is at test/sql/phase2_ddl.test:179.
</current_state>

<completed_work>

- Task 1: Resolve host DB path via PRAGMA database_list — DONE and committed (commit 1e24914)
- Task 2 (partial): Background writer thread implemented in catalog.rs, lib.rs, define.rs, drop.rs — compiles, clippy clean, 13 unit tests pass, SQLLogicTest sections 1-9 pass BUT section 10 (restart) fails
</completed_work>

<remaining_work>

- Fix restart test: after `restart`, `init_catalog` reads `semantic_layer._definitions` and gets 0 rows instead of 1
- Commit the fix
- Create SUMMARY.md for plan 02-04
- Update STATE.md and ROADMAP.md
- Trigger verifier re-run for phase 02
</remaining_work>

<decisions_made>

- **Rejected `Connection::open(db_path)` from invoke**: deadlocks (DuckDB holds per-DB lock during scalar function invoke)
- **Rejected `try_clone()` from invoke**: same spinlock issue — sharing same in-process DB instance causes DuckDB spinlock at 99% CPU
- **Chosen approach: background thread + `Connection::open(db_path)`** on a SEPARATE OS thread (not within invoke). The background thread owns its own connection. invoke sends op via `std::sync::mpsc::SyncSender` and blocks on reply. This is outside DuckDB's invoke lock so it CAN execute SQL safely.
- **CHECKPOINT after each write**: Added `con.execute_batch("CHECKPOINT")` after INSERT/DELETE in background thread to ensure WAL is flushed to disk before restart. Still not working.
- **Removed diagnostic query**: `SELECT FROM semantic_layer._definitions` mid-session was removed from section 10 because it fails (different MVCC snapshot). Only `list_semantic_views()` (HashMap-based) is tested mid-session.
</decisions_made>

<blockers>

- **Restart test fails**: After `restart`, `init_catalog` on the new connection reads `semantic_layer._definitions` and gets 0 rows.

  Root cause hypothesis: DuckDB opens TWO separate in-process database instances for the same file path (Python's `duckdb.connect(path)` and Rust's `Connection::open(path)` use separate DuckDB database handles). The INSERT from the Rust background thread goes into Rust's in-process database #2, which is separate from Python's database #1. Even with CHECKPOINT, DuckDB may not flush in a way that's readable by a freshly created Python connection.

  **Things to try next session:**
  1. Confirm the INSERT is actually reaching the file: after the test fails, check `sqlite3` or `duckdb` CLI on restart_test.db to see if the row is there
  2. Try `FORCE CHECKPOINT` instead of `CHECKPOINT` in the background thread
  3. Try calling `CHECKPOINT` via the PYTHON connection after define_semantic_view returns (add a `CHECKPOINT` statement in section 10 of the test between define and restart)
  4. Consider whether the background thread needs to use a DIFFERENT path to share the Python DuckDB instance — e.g., using `duckdb_connect()` C API to get a connection to the SAME underlying database handle as the host
  5. Alternative: store definitions as a JSON file (sidecar) written from the background thread via `std::fs::write`. Avoids all DuckDB concurrency issues entirely. Simpler.
</blockers>

<context>
The architecture is correct: background thread + channel + synchronous reply works for sections 1-9 (in-memory DB). The HashMap is always up to date. The only issue is cross-restart persistence via the DuckDB file.

The key insight: Rust's `Connection::open(path)` and Python's `duckdb.connect(path)` create SEPARATE in-process DuckDB database instances that share the same file. They communicate via the WAL/checkpoint mechanism. This is different from `try_clone()` which shares the same instance.

The CHECKPOINT approach should work in theory but may have a race condition or DuckDB-specific behavior that prevents it from working.

The JSON sidecar approach would bypass all of this complexity:
- Background thread writes `HashMap` as JSON to `{db_path}.semantic_views.json`
- `init_catalog` reads the JSON file to populate HashMap (and optionally populates the DuckDB table for SQL queryability)
- No DuckDB cross-connection issues
- Simple, reliable, 5 minutes to implement

Current uncommitted files: src/catalog.rs, src/ddl/define.rs, src/ddl/drop.rs, src/lib.rs, test/sql/phase2_ddl.test
Previous commit: 1e24914 (pragma_database_list approach, wrong invoke path)
</context>

<next_action>
Start by checking what's in restart_test.db after the test fails to confirm whether the INSERT actually reached the file:
```bash
ls -la test/sql/restart_test.db* 2>/dev/null
duckdb test/sql/restart_test.db "SELECT * FROM semantic_layer._definitions"
```

If the row IS in the file but init_catalog doesn't see it, it's a read isolation issue.
If the row is NOT in the file, the CHECKPOINT isn't working — try FORCE CHECKPOINT or the JSON sidecar approach.

Most likely next step: implement JSON sidecar (fastest path to working DDL-05).
</next_action>
