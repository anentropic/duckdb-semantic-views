use std::ffi::{CStr, CString};
use std::os::raw::c_void;
use std::sync::atomic::{AtomicBool, Ordering};

use duckdb::{
    core::{DataChunkHandle, Inserter, LogicalTypeHandle, LogicalTypeId},
    vtab::{BindInfo, InitInfo, TableFunctionInfo, VTab, Value},
};
use libduckdb_sys as ffi;

use crate::catalog::CatalogState;
use crate::expand::{expand, suggest_closest, QueryRequest};
use crate::model::SemanticViewDefinition;

use super::error::QueryError;

// ---------------------------------------------------------------------------
// QueryState -- stored as extra_info on the table function
// ---------------------------------------------------------------------------

/// Shared state for the `semantic_query` table function.
///
/// Carries the catalog (in-memory view definitions) and a raw `duckdb_connection`
/// handle for executing expanded SQL via the C API. The connection is created
/// independently of the host connection by calling `duckdb_connect` on the same
/// database handle, avoiding lock conflicts with the host during query execution.
///
/// For the connection handle extraction strategy, see `extract_query_conn` in lib.rs.
#[derive(Clone)]
pub struct QueryState {
    pub catalog: CatalogState,
    /// Raw connection handle for SQL execution.
    pub conn: ffi::duckdb_connection,
}

// SAFETY: The `duckdb_connection` raw pointer is an opaque handle managed by DuckDB.
// It was created during `extension_entrypoint` and lives for the database session lifetime.
// DuckDB manages internal synchronization for connections.
unsafe impl Send for QueryState {}
unsafe impl Sync for QueryState {}

// ---------------------------------------------------------------------------
// BindData / InitData
// ---------------------------------------------------------------------------

/// Data computed at bind time: the expanded SQL, output schema, and metadata.
pub struct SemanticViewBindData {
    /// The SQL query generated by `expand()`, ready for execution.
    expanded_sql: String,
    /// Output column names (dimensions first, then metrics).
    column_names: Vec<String>,
    /// Output column types as DuckDB C API type enums (stored for error context).
    #[allow(dead_code)]
    column_type_ids: Vec<ffi::duckdb_type>,
}

// SAFETY: All fields are `Send + Sync` types.
unsafe impl Send for SemanticViewBindData {}
unsafe impl Sync for SemanticViewBindData {}

/// State tracked during function execution.
pub struct SemanticViewInitData {
    /// Signals when all rows have been emitted.
    done: AtomicBool,
}

// SAFETY: `AtomicBool` is `Send + Sync`.
unsafe impl Send for SemanticViewInitData {}
unsafe impl Sync for SemanticViewInitData {}

// ---------------------------------------------------------------------------
// FFI helpers
// ---------------------------------------------------------------------------

/// Execute a SQL string via the DuckDB C API and return the result.
///
/// The caller is responsible for calling `duckdb_destroy_result` on the returned
/// result when done.
///
/// # Safety
///
/// `conn` must be a valid, non-null `duckdb_connection` handle.
unsafe fn execute_sql_raw(
    conn: ffi::duckdb_connection,
    sql: &str,
) -> Result<ffi::duckdb_result, String> {
    let sql_cstr = CString::new(sql).map_err(|e| e.to_string())?;
    let mut result: ffi::duckdb_result = std::mem::zeroed();
    let rc = ffi::duckdb_query(conn, sql_cstr.as_ptr(), &mut result);
    if rc != ffi::DuckDBSuccess {
        let err_ptr = ffi::duckdb_result_error(&mut result);
        let err_msg = if err_ptr.is_null() {
            "unknown error".to_string()
        } else {
            CStr::from_ptr(err_ptr).to_string_lossy().into_owned()
        };
        ffi::duckdb_destroy_result(&mut result);
        return Err(err_msg);
    }
    Ok(result)
}

/// Create a `LogicalTypeHandle` from a DuckDB C API type enum.
///
/// Uses `duckdb_create_logical_type` for primitive types. Falls back to VARCHAR
/// for complex types (DECIMAL, LIST, STRUCT, etc.) since those require
/// additional parameters.
fn logical_type_from_duckdb_type(ty: ffi::duckdb_type) -> LogicalTypeHandle {
    // For primitive types, use the duckdb-rs factory.
    // For complex/unsupported types, default to VARCHAR.
    match ty {
        ffi::DUCKDB_TYPE_DUCKDB_TYPE_BOOLEAN => LogicalTypeHandle::from(LogicalTypeId::Boolean),
        ffi::DUCKDB_TYPE_DUCKDB_TYPE_TINYINT => LogicalTypeHandle::from(LogicalTypeId::Tinyint),
        ffi::DUCKDB_TYPE_DUCKDB_TYPE_SMALLINT => LogicalTypeHandle::from(LogicalTypeId::Smallint),
        ffi::DUCKDB_TYPE_DUCKDB_TYPE_INTEGER => LogicalTypeHandle::from(LogicalTypeId::Integer),
        ffi::DUCKDB_TYPE_DUCKDB_TYPE_BIGINT => LogicalTypeHandle::from(LogicalTypeId::Bigint),
        ffi::DUCKDB_TYPE_DUCKDB_TYPE_UTINYINT => LogicalTypeHandle::from(LogicalTypeId::UTinyint),
        ffi::DUCKDB_TYPE_DUCKDB_TYPE_USMALLINT => LogicalTypeHandle::from(LogicalTypeId::USmallint),
        ffi::DUCKDB_TYPE_DUCKDB_TYPE_UINTEGER => LogicalTypeHandle::from(LogicalTypeId::UInteger),
        ffi::DUCKDB_TYPE_DUCKDB_TYPE_UBIGINT => LogicalTypeHandle::from(LogicalTypeId::UBigint),
        ffi::DUCKDB_TYPE_DUCKDB_TYPE_FLOAT => LogicalTypeHandle::from(LogicalTypeId::Float),
        ffi::DUCKDB_TYPE_DUCKDB_TYPE_DOUBLE => LogicalTypeHandle::from(LogicalTypeId::Double),
        ffi::DUCKDB_TYPE_DUCKDB_TYPE_TIMESTAMP => LogicalTypeHandle::from(LogicalTypeId::Timestamp),
        ffi::DUCKDB_TYPE_DUCKDB_TYPE_DATE => LogicalTypeHandle::from(LogicalTypeId::Date),
        ffi::DUCKDB_TYPE_DUCKDB_TYPE_TIME => LogicalTypeHandle::from(LogicalTypeId::Time),
        ffi::DUCKDB_TYPE_DUCKDB_TYPE_VARCHAR => LogicalTypeHandle::from(LogicalTypeId::Varchar),
        ffi::DUCKDB_TYPE_DUCKDB_TYPE_BLOB => LogicalTypeHandle::from(LogicalTypeId::Blob),
        ffi::DUCKDB_TYPE_DUCKDB_TYPE_HUGEINT => LogicalTypeHandle::from(LogicalTypeId::Hugeint),
        _ => LogicalTypeHandle::from(LogicalTypeId::Varchar), // Safe fallback
    }
}

/// Extract the raw `duckdb_value` pointer from a `duckdb::vtab::Value`.
///
/// The `Value` struct has a single field `ptr: duckdb_value` (which is `*mut c_void`),
/// but it is `pub(crate)` and inaccessible from external crates.  Since both types
/// are exactly one pointer wide, transmute is a safe layout conversion.
///
/// The returned pointer is valid only for the lifetime of the `Value` (it is NOT
/// destroyed; the `Value` still owns it).
///
/// # Safety
///
/// Relies on `duckdb::vtab::Value` layout being a single `duckdb_value` field.
/// This is stable for `duckdb = "=1.4.4"`.
unsafe fn value_raw_ptr(value: &Value) -> ffi::duckdb_value {
    // Value is repr(Rust) with one field: duckdb_value (*mut c_void).
    // Reading the pointer without taking ownership.
    let ptr_to_value = std::ptr::from_ref(value).cast::<ffi::duckdb_value>();
    std::ptr::read(ptr_to_value)
}

/// Extract string elements from a DuckDB LIST(VARCHAR) value.
///
/// Uses the C API `duckdb_get_list_size` and `duckdb_get_list_child` to iterate
/// the list, then `duckdb_get_varchar` on each child element.
///
/// # Safety
///
/// `value` must represent a LIST(VARCHAR) value.
unsafe fn extract_list_strings(value: &Value) -> Vec<String> {
    let value_ptr = value_raw_ptr(value);
    let size = ffi::duckdb_get_list_size(value_ptr);
    let mut result = Vec::with_capacity(size as usize);
    for i in 0..size {
        let child = ffi::duckdb_get_list_child(value_ptr, i);
        let cstr = ffi::duckdb_get_varchar(child);
        if !cstr.is_null() {
            let s = CStr::from_ptr(cstr).to_string_lossy().into_owned();
            ffi::duckdb_free(cstr.cast::<c_void>());
            result.push(s);
        }
        ffi::duckdb_destroy_value(&mut { child });
    }
    result
}

// ---------------------------------------------------------------------------
// VTab implementation
// ---------------------------------------------------------------------------

/// The `semantic_query` table function.
///
/// Registered as a single generic function that accepts a view name as a
/// positional parameter and optional `dimensions` / `metrics` as named
/// `LIST(VARCHAR)` parameters.
///
/// Usage:
/// ```sql
/// FROM semantic_query('my_view', dimensions := ['region'], metrics := ['total_revenue'])
/// ```
pub struct SemanticViewVTab;

impl VTab for SemanticViewVTab {
    type BindData = SemanticViewBindData;
    type InitData = SemanticViewInitData;

    fn bind(bind: &BindInfo) -> Result<Self::BindData, Box<dyn std::error::Error>> {
        // 1. Extract the view name (positional parameter 0).
        let view_name = bind.get_parameter(0).to_string();

        // 2. Extract dimensions and metrics from named LIST(VARCHAR) parameters.
        //    Use the raw duckdb_value FFI to iterate list elements.
        let dimensions = match bind.get_named_parameter("dimensions") {
            Some(ref val) => unsafe { extract_list_strings(val) },
            None => vec![],
        };
        let metrics = match bind.get_named_parameter("metrics") {
            Some(ref val) => unsafe { extract_list_strings(val) },
            None => vec![],
        };

        // 3. Validate: at least one dimension or metric.
        if dimensions.is_empty() && metrics.is_empty() {
            return Err(Box::new(QueryError::EmptyRequest {
                view_name: view_name.clone(),
            }));
        }

        // 4. Look up view definition in the catalog.
        let state_ptr = bind.get_extra_info::<QueryState>();
        let state = unsafe { &*state_ptr };
        let catalog_guard = state.catalog.read().expect("catalog RwLock poisoned");

        let json_str = match catalog_guard.get(&view_name) {
            Some(j) => j.clone(),
            None => {
                let available: Vec<String> = catalog_guard.keys().cloned().collect();
                let suggestion = suggest_closest(&view_name, &available);
                return Err(Box::new(QueryError::ViewNotFound {
                    name: view_name,
                    suggestion,
                    available,
                }));
            }
        };
        // Release the catalog lock before proceeding.
        drop(catalog_guard);

        // 5. Parse definition and expand.
        let def = SemanticViewDefinition::from_json(&view_name, &json_str)
            .map_err(|e| -> Box<dyn std::error::Error> { e.into() })?;
        let req = QueryRequest {
            dimensions: dimensions.clone(),
            metrics: metrics.clone(),
        };
        let expanded_sql = expand(&view_name, &def, &req)
            .map_err(|e| -> Box<dyn std::error::Error> { Box::new(QueryError::from(e)) })?;

        // 6. Infer output schema.
        //    Try executing the expanded SQL with LIMIT 0 to discover column types.
        //    If that fails (e.g., re-entrant SQL not allowed in bind), fall back
        //    to defaults: dimensions -> VARCHAR, metrics -> DOUBLE.
        let (column_names, column_type_ids) =
            infer_schema_or_default(state.conn, &expanded_sql, &dimensions, &metrics, &def);

        // 7. Declare output columns.
        for (name, &ty) in column_names.iter().zip(&column_type_ids) {
            bind.add_result_column(name, logical_type_from_duckdb_type(ty));
        }

        Ok(SemanticViewBindData {
            expanded_sql,
            column_names,
            column_type_ids,
        })
    }

    fn init(_: &InitInfo) -> Result<Self::InitData, Box<dyn std::error::Error>> {
        Ok(SemanticViewInitData {
            done: AtomicBool::new(false),
        })
    }

    fn func(
        func: &TableFunctionInfo<Self>,
        output: &mut DataChunkHandle,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let init_data = func.get_init_data();

        // If already done, signal completion.
        if init_data.done.swap(true, Ordering::Relaxed) {
            output.set_len(0);
            return Ok(());
        }

        let bind_data = func.get_bind_data();
        let state = unsafe { &*func.get_extra_info::<QueryState>() };

        // Execute the expanded SQL via the raw FFI connection.
        let mut result = unsafe {
            execute_sql_raw(state.conn, &bind_data.expanded_sql).map_err(|e| {
                QueryError::SqlExecution {
                    expanded_sql: bind_data.expanded_sql.clone(),
                    duckdb_error: e,
                }
            })?
        };

        // Fetch data and copy to output chunks.
        // DuckDB table functions emit data in chunks. We fetch all result chunks
        // from the FFI result and copy them to the output. For simplicity in v0.1,
        // we materialize ALL rows into a single output chunk call. If the result
        // exceeds DataChunkHandle capacity, we will need pagination (deferred).
        //
        // Strategy: read all result data as VARCHAR strings and insert via flat_vector.
        // This works regardless of the actual column type because DuckDB handles
        // implicit casting from VARCHAR to the declared output type.
        let col_count = unsafe { ffi::duckdb_column_count(&mut result) } as usize;
        let chunk_count = unsafe { ffi::duckdb_result_chunk_count(result) } as usize;

        // Collect all rows as string vectors.
        let mut all_rows: Vec<Vec<String>> = Vec::new();

        for chunk_idx in 0..chunk_count {
            let chunk = unsafe { ffi::duckdb_result_get_chunk(result, chunk_idx as ffi::idx_t) };
            if chunk.is_null() {
                continue;
            }
            let row_count = unsafe { ffi::duckdb_data_chunk_get_size(chunk) } as usize;

            for row_idx in 0..row_count {
                let mut row: Vec<String> = Vec::with_capacity(col_count);
                for col_idx in 0..col_count {
                    let vector =
                        unsafe { ffi::duckdb_data_chunk_get_vector(chunk, col_idx as ffi::idx_t) };

                    // Check for NULL using the validity mask.
                    let validity = unsafe { ffi::duckdb_vector_get_validity(vector) };
                    let is_null = if validity.is_null() {
                        false // All valid when no validity mask
                    } else {
                        // Check bit at row_idx position
                        let entry_idx = row_idx / 64;
                        let bit_idx = row_idx % 64;
                        unsafe {
                            let entry = *validity.add(entry_idx);
                            entry & (1u64 << bit_idx) == 0
                        }
                    };

                    if is_null {
                        row.push(String::new()); // NULL represented as empty string
                    } else {
                        // Use duckdb_get_varchar on a value extracted from the result.
                        // For simplicity, use the deprecated but functional
                        // duckdb_value_varchar approach via column value extraction.
                        let val = unsafe {
                            ffi::duckdb_value_varchar(
                                &mut result,
                                col_idx as ffi::idx_t,
                                row_idx as ffi::idx_t,
                            )
                        };
                        if val.is_null() {
                            row.push(String::new());
                        } else {
                            let s = unsafe { CStr::from_ptr(val).to_string_lossy().into_owned() };
                            unsafe { ffi::duckdb_free(val.cast::<c_void>()) };
                            row.push(s);
                        }
                    }
                }
                all_rows.push(row);
            }

            unsafe {
                ffi::duckdb_destroy_data_chunk(&mut { chunk });
            }
        }

        // Write rows to the output DataChunkHandle.
        let n = all_rows.len();
        if n > 0 {
            for col_idx in 0..bind_data.column_names.len().min(col_count) {
                let out_vec = output.flat_vector(col_idx);
                for (row_idx, row) in all_rows.iter().enumerate() {
                    out_vec.insert(row_idx, row[col_idx].as_str());
                }
            }
        }
        output.set_len(n);

        unsafe {
            ffi::duckdb_destroy_result(&mut result);
        }

        Ok(())
    }

    fn parameters() -> Option<Vec<LogicalTypeHandle>> {
        // Positional parameter: view_name (VARCHAR)
        Some(vec![LogicalTypeHandle::from(LogicalTypeId::Varchar)])
    }

    fn named_parameters() -> Option<Vec<(String, LogicalTypeHandle)>> {
        Some(vec![
            (
                "dimensions".to_string(),
                LogicalTypeHandle::list(&LogicalTypeHandle::from(LogicalTypeId::Varchar)),
            ),
            (
                "metrics".to_string(),
                LogicalTypeHandle::list(&LogicalTypeHandle::from(LogicalTypeId::Varchar)),
            ),
        ])
    }
}

// ---------------------------------------------------------------------------
// Schema inference
// ---------------------------------------------------------------------------

/// Try to infer the output schema by executing the expanded SQL with LIMIT 0.
///
/// If schema inference succeeds, returns the actual column names and DuckDB type
/// enums from DuckDB's type inference. If it fails (e.g., re-entrant SQL blocked
/// in bind), falls back to default types: dimension columns as VARCHAR, metric
/// columns as DOUBLE.
fn infer_schema_or_default(
    conn: ffi::duckdb_connection,
    expanded_sql: &str,
    dimensions: &[String],
    metrics: &[String],
    def: &SemanticViewDefinition,
) -> (Vec<String>, Vec<ffi::duckdb_type>) {
    // Try LIMIT 0 for accurate type inference.
    let limit0_sql = format!("{expanded_sql} LIMIT 0");
    let inferred = unsafe { try_infer_schema(conn, &limit0_sql) };

    if let Some((names, types)) = inferred {
        return (names, types);
    }

    // Fallback: derive schema from definition metadata.
    let mut column_names = Vec::new();
    let mut column_types = Vec::new();

    for dim_name in dimensions {
        // Use the definition's canonical name casing.
        let canonical = def
            .dimensions
            .iter()
            .find(|d| d.name.eq_ignore_ascii_case(dim_name))
            .map_or_else(|| dim_name.clone(), |d| d.name.clone());
        column_names.push(canonical);
        column_types.push(ffi::DUCKDB_TYPE_DUCKDB_TYPE_VARCHAR);
    }
    for met_name in metrics {
        let canonical = def
            .metrics
            .iter()
            .find(|m| m.name.eq_ignore_ascii_case(met_name))
            .map_or_else(|| met_name.clone(), |m| m.name.clone());
        column_names.push(canonical);
        column_types.push(ffi::DUCKDB_TYPE_DUCKDB_TYPE_DOUBLE);
    }

    (column_names, column_types)
}

/// Attempt to infer column names and types by executing a LIMIT 0 query.
///
/// Returns `None` if the query fails for any reason.
///
/// # Safety
///
/// `conn` must be a valid `duckdb_connection`.
unsafe fn try_infer_schema(
    conn: ffi::duckdb_connection,
    sql: &str,
) -> Option<(Vec<String>, Vec<ffi::duckdb_type>)> {
    let mut result = execute_sql_raw(conn, sql).ok()?;

    let col_count = ffi::duckdb_column_count(&mut result) as usize;
    let mut names = Vec::with_capacity(col_count);
    let mut types = Vec::with_capacity(col_count);

    for i in 0..col_count {
        let name_ptr = ffi::duckdb_column_name(&mut result, i as ffi::idx_t);
        let name = if name_ptr.is_null() {
            format!("column{i}")
        } else {
            CStr::from_ptr(name_ptr).to_string_lossy().into_owned()
        };
        names.push(name);

        let ty = ffi::duckdb_column_type(&mut result, i as ffi::idx_t);
        types.push(ty);
    }

    ffi::duckdb_destroy_result(&mut result);
    Some((names, types))
}
